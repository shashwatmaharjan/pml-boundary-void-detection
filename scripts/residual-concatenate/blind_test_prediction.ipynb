{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fonts and fontsize for plotting\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['mathtext.fontset'] = 'dejavuserif'\n",
    "fontsize = 15\n",
    "fontsize_ticks = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define necessary functions\n",
    "# Function to get displacement and void data\n",
    "def get_data(file_directory):\n",
    "\n",
    "    # Load the displacement data\n",
    "    blind_test_displacement_data = loadmat(os.path.join(file_directory, 'blind_displacement_data.mat'))['displacement_data']\n",
    "\n",
    "    # Load the void data\n",
    "    blind_test_void_data = loadmat(os.path.join(file_directory, 'blind_void_data.mat'))['void_data']\n",
    "\n",
    "    return blind_test_displacement_data, blind_test_void_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize the displacement data\n",
    "def normalize_data(data, mean, range):\n",
    "\n",
    "    return (data - mean) / range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate metrics\n",
    "def metrics_calculator(target, predicted):\n",
    "\n",
    "    # True positive\n",
    "    tp = 0\n",
    "\n",
    "    # True negative\n",
    "    tn = 0\n",
    "\n",
    "    # False positive\n",
    "    fp = 0\n",
    "\n",
    "    # False negative\n",
    "    fn = 0\n",
    "\n",
    "    # Accuracy, Precision, Recall, F1 score\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "\n",
    "    for n_sample in range(target.shape[0]):\n",
    "\n",
    "        for n_element in range(target.shape[1]):\n",
    "            \n",
    "            # If both the target and predicted are same\n",
    "            if target[n_sample, n_element] == predicted[n_sample, n_element]:\n",
    "\n",
    "                # If the target and predicted are both 1\n",
    "                if target[n_sample, n_element] == 1 and predicted[n_sample, n_element] == 1:\n",
    "\n",
    "                    tp = tp + 1\n",
    "\n",
    "                # If the target and predicted are both 0\n",
    "                elif target[n_sample, n_element] == 0 and predicted[n_sample, n_element] == 0:\n",
    "\n",
    "                    tn = tn + 1\n",
    "            \n",
    "            # If the target and predicted are different\n",
    "            else:\n",
    "\n",
    "                # If the target is 0 and predicted is 1\n",
    "                if target[n_sample, n_element] == 0 and predicted[n_sample, n_element] == 1:\n",
    "\n",
    "                    fp = fp + 1\n",
    "                \n",
    "                # If the target is 1 and predicted is 0\n",
    "                elif target[n_sample, n_element] == 1 and predicted[n_sample, n_element] == 0:\n",
    "                \n",
    "                    fn = fn + 1\n",
    "            \n",
    "        # Calculate accuracy, precision, and recall\n",
    "        accuracy.append((tp + tn) / (tp + tn + fp + fn))\n",
    "        precision.append(tp / (tp + fp))\n",
    "        recall.append(tp / (tp + fn))\n",
    "    \n",
    "    # Convert the lists to numpy arrays\n",
    "    accuracy = np.array(accuracy)\n",
    "    precision = np.array(precision)\n",
    "    recall = np.array(recall)\n",
    "\n",
    "    # Calculate the F1 score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    return accuracy, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot void 0 prediction\n",
    "def plot_void(target, predicted, file_directory, f1_score):\n",
    "\n",
    "    for sample_num in range(len(target)):\n",
    "\n",
    "        # See how the actual void looks in target\n",
    "        actual_plot = plt.figure()\n",
    "        ax = plt.axes()\n",
    "        im1 = plt.imshow(target[sample_num, :, :], cmap='binary', origin='lower', vmin=0, vmax=1, extent=[0, 50, 0, 50])\n",
    "        \n",
    "        # Domain section lines\n",
    "        plt.axhline(y=10, color='k', linewidth = 0.5, linestyle='--', dashes=(10, 5))\n",
    "        plt.axhline(y=20, color='k', linewidth = 0.5)\n",
    "        plt.axhline(y=30, color='k', linewidth = 0.5)\n",
    "        plt.axhline(y=40, color='k', linewidth = 0.5)\n",
    "\n",
    "        plt.axvline(x=5, color='k', linewidth = 0.5, linestyle='--', dashes=(10, 5))\n",
    "        plt.axvline(x=45, color='k', linewidth = 0.5, linestyle='--', dashes=(10, 5))\n",
    "        \n",
    "        plt.xlabel('$x$ [m]', fontsize=fontsize)\n",
    "        plt.ylabel('$y$ [m]', fontsize=fontsize)\n",
    "        plt.title(f'Sample Number: {sample_num+1}', fontsize=fontsize_ticks)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=fontsize_ticks)\n",
    "        cax = actual_plot.add_axes([ax.get_position().x1+0.01,ax.get_position().y0,0.02,ax.get_position().height])\n",
    "        cb = plt.colorbar(im1, cax=cax)\n",
    "        cb.ax.tick_params(labelsize=fontsize_ticks)\n",
    "        plt.savefig(os.path.join(file_directory, f'sample_{sample_num+1}_void_target.pdf'), bbox_inches='tight')\n",
    "\n",
    "        # See how the predicted void looks in prediction\n",
    "        predicted_plot = plt.figure()\n",
    "        ax = plt.axes()\n",
    "        im2 = plt.imshow(predicted[sample_num, :], cmap='binary', origin='lower', vmin=0, vmax=1, extent=[0, 50, 0, 50])\n",
    "        \n",
    "        # Domain section lines\n",
    "        plt.axhline(y=10, color='k', linewidth = 0.5, linestyle='--', dashes=(10, 5))\n",
    "        plt.axhline(y=20, color='k', linewidth = 0.5)\n",
    "        plt.axhline(y=30, color='k', linewidth = 0.5)\n",
    "        plt.axhline(y=40, color='k', linewidth = 0.5)\n",
    "        \n",
    "        plt.axvline(x=5, color='k', linewidth = 0.5, linestyle='--', dashes=(10, 5))\n",
    "        plt.axvline(x=45, color='k', linewidth = 0.5, linestyle='--', dashes=(10, 5))\n",
    "\n",
    "        plt.xlabel('$x$ [m]', fontsize=fontsize)\n",
    "        plt.ylabel('$y$ [m]', fontsize=fontsize)\n",
    "        plt.title(f'Sample Number: {sample_num+1}; F1 score: {f1_score[sample_num]*100:.2f}%', fontsize=fontsize_ticks)   \n",
    "        ax.tick_params(axis='both', which='major', labelsize=fontsize_ticks)\n",
    "        cax = predicted_plot.add_axes([ax.get_position().x1+0.01,ax.get_position().y0,0.02,ax.get_position().height])\n",
    "        cb = plt.colorbar(im2, cax=cax)\n",
    "        cb.ax.tick_params(labelsize=fontsize_ticks)\n",
    "        plt.savefig(os.path.join(file_directory, f'sample_{sample_num+1}_void_predicted.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Define directory for the blind test data\n",
    "blind_test_data_directory = os.path.join(current_directory, '..', '..', 'blind_data', 'assembled')\n",
    "\n",
    "# Define directory for the normalizing parameters\n",
    "normalized_data_directory = os.path.join(current_directory, '..', '..', 'data', 'normalized')\n",
    "\n",
    "# Define directory for the trained model\n",
    "trained_results_directory = os.path.join(current_directory, '..', '..', 'residual', 'training_results')\n",
    "\n",
    "# Define directory for the prediction results\n",
    "prediction_results_directory = os.path.join(current_directory, '..', '..', 'residual', 'prediction_results', 'blind_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the blind test data\n",
    "blind_displacement_data, blind_void_data = get_data(blind_test_data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the normalizing parameters\n",
    "normalizing_parameters = loadmat(os.path.join(normalized_data_directory, 'normalizing_parameters.mat'))\n",
    "\n",
    "# Extract the normalizing parameters from the dictionary\n",
    "normalizing_parameters = normalizing_parameters['values']\n",
    "\n",
    "# Mean, min, and max values for normalizing the displacement data\n",
    "mean = normalizing_parameters['mean'][0][0][0]\n",
    "min_value = normalizing_parameters['min'][0][0][0]\n",
    "max_value = normalizing_parameters['max'][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the displacement data\n",
    "blind_displacement_data = normalize_data(blind_displacement_data, mean, max_value - min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(os.path.join(trained_results_directory, 'best_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to predict on the test data both probability and class\n",
    "threshold = 0.5\n",
    "void_predicted_void_data_probabilistic = model.predict(blind_displacement_data)\n",
    "void_predicted_void_data_class = np.where(void_predicted_void_data_probabilistic > threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the void prediction\n",
    "# Calculate the metrics\n",
    "accuracy, precision, recall, f1_score = metrics_calculator(blind_void_data, void_predicted_void_data_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the target and predicted data to a 50x50 grid\n",
    "void_target_void_data = np.reshape(blind_void_data, (blind_void_data.shape[0], 50, 50))\n",
    "void_predicted_void_data_probabilistic = np.reshape(void_predicted_void_data_probabilistic, (void_predicted_void_data_probabilistic.shape[0], 50, 50))\n",
    "\n",
    "# Plot the void prediction\n",
    "plot_void(void_target_void_data, void_predicted_void_data_probabilistic, prediction_results_directory, f1_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
