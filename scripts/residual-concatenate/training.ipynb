{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fonts and fontsize for plotting\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['mathtext.fontset'] = 'dejavuserif'\n",
    "fontsize = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define necessary functions\n",
    "# Function to get displacement and void data\n",
    "def get_data(file_directory, void_number):\n",
    "\n",
    "    # Load the displacement data\n",
    "    training_displacement_data = loadmat(os.path.join(file_directory, f'void_{void_number}_training_displacement_data_normalized.mat'))['displacement_data']\n",
    "    validation_displacement_data = loadmat(os.path.join(file_directory, f'void_{void_number}_validation_displacement_data_normalized.mat'))['displacement_data']\n",
    "\n",
    "    # Load the void data\n",
    "    training_void_data = loadmat(os.path.join(file_directory, f'void_{void_number}_training_void_data.mat'))['void_data']\n",
    "    validation_void_data = loadmat(os.path.join(file_directory, f'void_{void_number}_validation_void_data.mat'))['void_data']\n",
    "\n",
    "    return training_displacement_data, validation_displacement_data, training_void_data, validation_void_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual class\n",
    "class RESIDUAL():\n",
    "\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        \n",
    "        # Initialize input_layer here\n",
    "        self.input_layer = None  \n",
    "\n",
    "    # Method to build the hidden layers\n",
    "    def build_hidden_layers(self):\n",
    "        \n",
    "        # Convolutional Layers\n",
    "        # First Convolutional Layer\n",
    "        x1 = tf.keras.layers.Conv1D(filters=180, kernel_size=10, padding='same', activation='relu', kernel_initializer = 'glorot_normal')(self.input_layer)\n",
    "        x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "\n",
    "        # Second Convolutional Layer\n",
    "        x2 = tf.keras.layers.Conv1D(filters=180, kernel_size=10, padding='same', activation='relu', kernel_initializer = 'glorot_normal')(x1)\n",
    "        x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "        \n",
    "        # Skip concatenated connection\n",
    "        x2 = tf.keras.layers.Concatenate(axis=-1)([x1, x2])\n",
    "\n",
    "        return x2\n",
    "\n",
    "    # Method to build the overall model\n",
    "    def build_model(self):\n",
    "        \n",
    "        # Input layer\n",
    "        self.input_layer = tf.keras.layers.Input(shape=self.input_shape)\n",
    "\n",
    "        # Hidden layer\n",
    "        hidden_layer = self.build_hidden_layers()\n",
    "\n",
    "        # Add a flatten layer\n",
    "        flatten_layer = tf.keras.layers.Flatten()(hidden_layer)\n",
    "\n",
    "        # Output Layer\n",
    "        output_layer = tf.keras.layers.Dense(units=self.output_shape, activation='sigmoid')(flatten_layer)\n",
    "\n",
    "        # Build model\n",
    "        self.model = tf.keras.models.Model(inputs=[self.input_layer], outputs=[output_layer])\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    # Method to compile the model\n",
    "    def compile(self, optimizer, loss, evaluation_metric):\n",
    "        \n",
    "        # Compile model\n",
    "        self.model.compile(optimizer=optimizer, loss=loss, metrics=evaluation_metric)\n",
    "\n",
    "        return self.model\n",
    "    \n",
    "    # Define method to train the model\n",
    "    def train(self, x_train, y_train, x_val, y_val, epochs, batch_size, callbacks):\n",
    "        \n",
    "        # Train model\n",
    "        self.history = self.model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, callbacks=callbacks,\n",
    "                                      validation_data=(x_val, y_val))\n",
    "        \n",
    "        return self.history\n",
    "    \n",
    "    # Method to print summary of model\n",
    "    def summary(self):\n",
    "        \n",
    "        self.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class plots:\n",
    "    \n",
    "    def __init__(self, history, file_directory):\n",
    "\n",
    "        self.history = history\n",
    "        self.file_directory = file_directory\n",
    "\n",
    "    def loss(self):\n",
    "\n",
    "        loss_name = list(self.history.history.keys())[0]\n",
    "\n",
    "        # Training\n",
    "        loss = self.history.history[loss_name]\n",
    "        val_loss = self.history.history['val_' + loss_name]\n",
    "\n",
    "        loss_plot = plt.figure()\n",
    "        epochs = range(1, len(loss)+1)\n",
    "        plt.plot(epochs, loss, 'bo--', label = 'Training Loss', markersize = 2)\n",
    "        plt.plot(epochs, val_loss, 'go--', label = 'Validation Loss', markersize = 2)\n",
    "        plt.title('Training and Validation Loss', fontsize=fontsize)\n",
    "        plt.xlabel('Epochs', fontsize=fontsize)\n",
    "        plt.ylabel('Loss', fontsize=fontsize)\n",
    "        plt.legend(['Training Loss', 'Validation Loss'], fontsize=fontsize)\n",
    "        ax = loss_plot.gca()\n",
    "        ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        plt.savefig(self.file_directory + '/loss.pdf', bbox_inches='tight')\n",
    "        \n",
    "        return loss_plot\n",
    "\n",
    "    def evaluation_metric(self):\n",
    "\n",
    "        metric_name = list(self.history.history.keys())[1]\n",
    "        \n",
    "        # Training\n",
    "        metric = self.history.history[metric_name]\n",
    "        val_metric = self.history.history['val_' + metric_name]\n",
    "\n",
    "        metric_plot = plt.figure()\n",
    "        epochs = range(1, len(metric)+1)\n",
    "        plt.plot(epochs, metric, 'bo--', label = 'Training Metric', markersize = 2)\n",
    "        plt.plot(epochs, val_metric, 'go--', label = 'Validation Metric', markersize = 2)\n",
    "        plt.title('Training and Validation Evaluation Metric', fontsize=fontsize)\n",
    "        plt.xlabel('Epochs', fontsize=fontsize)\n",
    "        plt.ylabel('Evaluation Metric', fontsize=fontsize)\n",
    "        plt.legend(['Training Metric', 'Validation Metric'], fontsize=fontsize)\n",
    "        ax = metric_plot.gca()\n",
    "        ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        plt.savefig(self.file_directory + '/evaluation_metric.pdf', bbox_inches='tight')\n",
    "\n",
    "        return metric_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Define directory for the normalized data\n",
    "normalized_data_directory = os.path.join(current_directory, '..', '..', 'data', 'normalized')\n",
    "\n",
    "# Define directory for the trained results\n",
    "trained_results_directory = os.path.join(current_directory, '..', '..', 'residual-concatenate', 'training_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the normalized data for all three voids\n",
    "void_0_training_displacement_data, void_0_validation_displacement_data, void_0_training_void_data, void_0_validation_void_data = get_data(normalized_data_directory, 0)\n",
    "void_1_training_displacement_data, void_1_validation_displacement_data, void_1_training_void_data, void_1_validation_void_data = get_data(normalized_data_directory, 1)\n",
    "void_2_training_displacement_data, void_2_validation_displacement_data, void_2_training_void_data, void_2_validation_void_data = get_data(normalized_data_directory, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertically stack the training, validation and test data\n",
    "# Displacement\n",
    "training_displacement_data = np.vstack((void_0_training_displacement_data, void_1_training_displacement_data, void_2_training_displacement_data))\n",
    "validation_displacement_data = np.vstack((void_0_validation_displacement_data, void_1_validation_displacement_data, void_2_validation_displacement_data))\n",
    "\n",
    "# Void\n",
    "training_void_data = np.vstack((void_0_training_void_data, void_1_training_void_data, void_2_training_void_data))\n",
    "validation_void_data = np.vstack((void_0_validation_void_data, void_1_validation_void_data, void_2_validation_void_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomize the dataset using the same seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Randomize the training data\n",
    "random_indices = np.random.permutation(training_displacement_data.shape[0])\n",
    "training_displacement_data = training_displacement_data[random_indices]\n",
    "training_void_data = training_void_data[random_indices]\n",
    "\n",
    "# Randomize the validation data\n",
    "random_indices = np.random.permutation(validation_displacement_data.shape[0])\n",
    "validation_displacement_data = validation_displacement_data[random_indices]\n",
    "validation_void_data = validation_void_data[random_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables that remain constant during the training\n",
    "input_shape = void_0_training_displacement_data.shape[1:]\n",
    "output_shape = void_0_training_void_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the residual class\n",
    "model = RESIDUAL(input_shape, output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and the model\n",
    "model.build_model()\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001), loss = 'binary_crossentropy', evaluation_metric = tf.metrics.Precision(name='precision'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "# Early stopping callback\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 5, mode = 'min', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print('Training the model...')\n",
    "history = model.train(training_displacement_data, training_void_data, \n",
    "                      validation_displacement_data, validation_void_data,\n",
    "                      epochs = 1000, \n",
    "                      batch_size = 32,\n",
    "                      callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plots(history, trained_results_directory)\n",
    "loss_plot = plot.loss()\n",
    "evaluation_metric_plot = plot.evaluation_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "print('Saving the model...')\n",
    "model.model.save(os.path.join(trained_results_directory, 'model.h5'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
